{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c767a35f-67d7-466e-ae99-3513146a2bee",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../imagens/logo_APL.png\" width=\"300\" alt=\"APL logo\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ec966-2eed-48e9-8b4c-214f4c970871",
   "metadata": {},
   "source": [
    "# Uma Introdução à Biblioteca `Scikit-Learn` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84856c-5c26-462e-8919-8e0dc5384645",
   "metadata": {},
   "source": [
    "**Bem vindo!** Neste notebook será abordada a biblioteca `Scikit-Learn`, desenvolvida especificamente para aplicação prática de algoritmos de *machine learning*. Ao final, espera-se que você seja capaz de usar as ferramentas simples e eficientes para análise preditiva de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead5e39-4245-4e52-b3a9-eafc2c2e703b",
   "metadata": {},
   "source": [
    "<h2>Conteúdo:</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ul>\n",
    "    <li> Introdução </li>\n",
    "    <li> Exemplo Completo de Machine Learning:  \n",
    "        <ul>\n",
    "            <li> Carregamento do Dataset </li> \n",
    "            <li> Separar as Colunas do Dataframe: Regressores vs Variável Alvo </li>     \n",
    "            <li> Problema de *Overfitting* </li>\n",
    "            <li> Dividir o Dataset: Treinamento e Validação </li>   \n",
    "            <li> Algoritmo de Machine Learning </li>  \n",
    "            <li> Avaliação de Desempenho </li>  \n",
    "        </ul>\n",
    "    </li> \n",
    "    <li> Discussão e Próximos Passos </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a72d74-0f1a-43e4-8965-9cc051d2f495",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Esta introdução tem por objetivo fornecer de forma simples e objetiva uma apresentação às principais ferramentas fornecidas pela biblioteca `Scikit_learn`.  Ao final desse módulo espera-se que você seja capaz de aplicar as principais ferramentas dessa biblioteca em um problema de *Machine Learning*.\n",
    "\n",
    "Vamos começar importando as principais bibliotecas a serem utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d208a3-33f6-405c-a941-4f118eb6ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3ff37-d378-49e2-bc3d-ec475f0685b0",
   "metadata": {},
   "source": [
    "## Exemplo Completo de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1064cb1-a809-44d0-ae00-53d28f53bc7a",
   "metadata": {},
   "source": [
    "Será apresentado um exemplo completo de *machine learning* desde o carregamento do dataset, treinamento do modelo, predição e avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4a20b-e177-4cc4-a363-5e7f3e2bfba3",
   "metadata": {},
   "source": [
    "### Carregamento do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c18533-294e-4e21-8349-7372df3ea60b",
   "metadata": {},
   "source": [
    "Vamos carregar nosso dataset.\n",
    "O exemplo é baseado em um conjunto de dados que está publicamente disponível no [UCI Machine Learning Repository](http://mlearn.ics.uci.edu/MLRepository.html). Esse conjunto de dados consiste em centenas de registros de amostras de células humanas, contendo diversas características. Os campos em cada registro são:\n",
    "\n",
    "| Nome        | Descrição                             |\n",
    "| ----------- | ---------------------------           |\n",
    "| ID          | Identificação                         |\n",
    "| Clump       | espessura do aglomerado               |\n",
    "| UnifSize    | Uniformidade do tamanho da célula     |\n",
    "| UnifShape   | Uniformidade do formato da célula     |\n",
    "| MargAdh     | Adesão marginal                       |\n",
    "| SingEpiSize | Tamanho de célula epitelial única     |\n",
    "| BareNuc     | Núcleos puros                         |\n",
    "| BlandChrom  | Cromatina branda                      |\n",
    "| NormNucl    | Nucléolos normais                     |\n",
    "| Mit         | Mitoses                               |\n",
    "| Class       | Benigno ou Maligno                    |\n",
    "\n",
    "\n",
    "Para fins de simplificação, estamos usando um conjunto de dados que possui um número relativamente pequeno de preditores ou regressores ou *features* (no presente contexto, esses termos são equivalentes) em cada registro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123db39-83c3-41f2-b408-e24f9cc39194",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df = pd.read_csv(\"https://raw.githubusercontent.com/APL-Data-Intelligence/AcelerAI/main/Curso_NEED/datasets/cellsample_dataset/cell_samples.csv\")\n",
    "cell_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fca73-26c1-4486-9c8b-f658e80f98ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "Nosso dataset possui, portanto, 699 amostras e 11 características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d46d90-10ff-4409-af9d-7c4e498fa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fe49c-14d2-4548-89af-985089985b7b",
   "metadata": {},
   "source": [
    "### Separar as Colunas do Dataframe: Regressores vs Variável Alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a0bdc-aacb-4b76-a55a-770f1e2ae616",
   "metadata": {},
   "source": [
    "Os regressores ou features (atributos) são as variáveis explicativas do nosso dataset. Enquanto a variável alvo reflete a característica que desejamos classificar: em nosso dataset, se o câncer é benigno ou malígno.\n",
    "\n",
    "Para essa finalidade, vamos criar um novo dataframe a partir do dataframe orignal, utilizando-se as features desejadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5479fdc-7af2-47eb-b278-5a5c81ce1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BlandChrom', 'NormNucl', 'Mit']]\n",
    "X = np.asarray(feature_df)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908324a-fa8b-4332-a840-133971932b77",
   "metadata": {},
   "source": [
    "Agora vamos criar o nosso dataframe que corresponde a variável alvo, ou seja, a variável que queremos fazer a predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03149d2d-d579-4a8c-8a6f-3332034b0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df['Class'] = cell_df['Class'].astype('int')\n",
    "y = np.asarray(cell_df['Class'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d410d3d-3adf-4220-9629-3423df2b2525",
   "metadata": {},
   "source": [
    "## Problema de *Overfitting*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a4ae11-9480-4e37-8e2b-13ec301b5def",
   "metadata": {},
   "source": [
    "Suponha que você possui uma base de dados a ser utilizada para o treinamento de um classificador e, na sequência, avaliar o seu desempenho. \n",
    "\n",
    "Ao realizar o treinamento, você pode pensar em usar o mesmo conjunto de dados para avaliá-lo. Entretanto, o resultado obtido poderá não refletir a capacidade de generalização do seu modelo. De fato, o seu modelo será enviesado, correndo o risco de se ter um sobreajuste de aderência aos dados. \n",
    "\n",
    "Esse problema, conhecido como *overfitting*, é bastante comum em *Machine Learning*. \n",
    "\n",
    "A figura abaixo apresenta uma comparação entre dois classificadores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527c2d9-1a3e-4944-8c23-aa4b6e91f1ec",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../imagens/Overfitting.png\" width=\"300\"\" alt=\"Overfitting\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b39366-2509-4560-98ac-e595b7eba2f6",
   "metadata": {},
   "source": [
    "Observe que o classificador representado na cor preta é capaz de propor uma separação adequada, mas comete alguns errros. Po outro lado, o classificador indicado pela cor verde não comete nenhum erro de classificação. Mas, pode-se observar o sobreajuste aos dados. \n",
    "\n",
    "Provavelmente, o classificador representado cor preta possui um poder de generalização maior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079a695-ee0c-437f-8869-6d94281a774c",
   "metadata": {},
   "source": [
    "## Dividir o Dataset: Treinamento e Validação/Teste\n",
    "\n",
    "Uma solução bastante conhecida para minimizar esse problema é separar a base de dados em dois subconjuntos, que são mutuamente exclusivos:  um para treinamento e outro para validação/teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd5aa1-1b11-473c-b9de-b081079b07d9",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../imagens/treino_teste.png\" width=500\"\" alt=\"Divisão da Base de Dados\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31454e-a8f1-4e49-9a88-33bc6fb53d8a",
   "metadata": {},
   "source": [
    "Isso fornecerá uma avaliação mais satisfatória porque o conjunto de dados de teste não faz parte do conjunto de dados que foi usado para treinamento. Essa abordagem é adequada para problemas do mundo real, uma vez que o objetivo de qualquer modelo é fazer previsões corretas sobre dados desconhecidos.\n",
    "\n",
    "Para se verficar a eficácia e o poder de generalização do modelo deve-se, portanto, usar a métrica obtida a partir dos dados de validação/teste. Uma dessas métricas é o percentual de previsões corretas que o modelo faz sobre os dados de validação, conhecida como *acurácia de validação*, do inglês *Out-of-Sample Accuracy*.\n",
    "\n",
    "Vamos, portanto, dividir nosso dataset em duas partes: 1) dados de treinamento; e 2) dados de validação. Para tanto, vamos utilizar o método `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3347fe2-830a-42f1-9353-fe2a6def6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47fa5c-a88e-4ab7-b046-a5cecf3e7002",
   "metadata": {},
   "source": [
    "O método `train_test_split` possui os seguintes parâmetros de entrada: `X`, `y`, `test_size` e `random_state`. \n",
    "- `X` e `y` reprentam os regressores e a variável alvo, respectivamente;\n",
    "- `test_size` indica a proporlçao de dados presentes no conjunto de validaçãoç  e \n",
    "- `random_state`  garante que obtenhamos as mesmas divisões entre os dados mesmo em diferentes execuções desse algoritmo.\n",
    "\n",
    "Como saída, `train_test_split` retornará 4 variáveis, que chamamos de: `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c9ae3-fc27-4532-b6d0-a4eaa89b49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d22f6-462c-4d5e-a292-54a37f521a3f",
   "metadata": {},
   "source": [
    "Vamos mostrar a dimensão desses conjuntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05784e80-1df9-40c3-af76-ea2744cb9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Conjunto de treino:', X_train.shape,  y_train.shape)\n",
    "print ('Conjunto de teste:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409dd9cd-4b27-4a61-a132-b243953c9bc8",
   "metadata": {},
   "source": [
    "Podemos observar que nosso **conjunto de treinamento** possui 559 amostras (ou 80%), enquanto o **conjunto de avaliação** 140 amostras (ou 20%), totalizando as 699 amostras originais. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91aab3-40e6-4afa-b325-1f21ef620aac",
   "metadata": {},
   "source": [
    "## Algoritmo de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab6b0-5122-40bb-8c87-599605446ecb",
   "metadata": {},
   "source": [
    "Nessa etapa escolhemos o algoritmo de machine learning que desejamos utilizar. Nesse nosso exemplo vamos escolher o algoritmo **Árvore de Decisão** (em inglês, *Decision Tree*). Iremos discutir esse algorimo em detalhes no próximo Módulo.\n",
    "\n",
    "#### **Passo 1:** Importando a componente do classificador. \n",
    "- No nosso exemplo vamos usar **Árvore de Decisão**, na biblioteca `sklearn.DecisionTreeClassifier()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999072c6-d291-4a46-95b1-d48256a5a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eda479-78ab-46c8-be4a-f5b7caef5947",
   "metadata": {},
   "source": [
    "#### **Passo 2**: Instanciando o Estimador. \n",
    "- \"Estimador (em inglês, *Estimator*)\" é o termo do `scikit-learn` para modelo;\n",
    "- \"Instanciar\" significa \"criar uma instância de\";\n",
    "- Nesse exemplo utilizamos uma Árvores de Decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46584b1f-a00d-4940-9354-de68c88ebc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad311d2-713f-4a49-a1de-c0d4ba2174d3",
   "metadata": {},
   "source": [
    "- O nome do objeto fica a escolha do programador (nesse exemplo, usamos **DTC**);\n",
    "- Podemos especificar parâmetros de ajuste (também conhecidos como \"hiperparâmetros\") durante esta etapa;\n",
    "- Todos os parâmetros não especificados são definidos para seus *dafault* (valores padrâo). Como esse nosso exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1474fe2-26d9-4f3a-8ce4-1222063e2d08",
   "metadata": {},
   "source": [
    "#### **Passo 3**: Ajustar os parâmetros do modelo a partir dos dados\n",
    "\n",
    "- Etapa de treinamento do modelo;\n",
    "- Modelo está tentando aprender a relação de mapeamento entre a entrada X e a saída y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4481b-524f-4598-b70e-91cdf100d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0360e-f9b4-4de0-8819-c70d9bfd0685",
   "metadata": {},
   "source": [
    "#### **Passo 4:** Fazer a predição a partir de um novo comjunto de amostras:\n",
    "\n",
    "- Novas amostras (dados que não foram usados no treinamento) são chamados *\"out-of-sample\" data*;\n",
    "- O algoritmo vai usar as relações que foram aprendidas durante o processo de treinamento do modelo;\n",
    "- Vamos usar o conjunto de **teste** na predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ce337-2778-4bbc-803e-0bd29cfffb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "y_pred = DTC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151c482-5c8f-4e55-87b8-71667f338a17",
   "metadata": {},
   "source": [
    "## Avaliação de Desempenho\n",
    "\n",
    "Vamos mostrar os valores de nosso dataset de validação e comparar com algumas predições feitas pelo nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e9907-0595-4828-aad3-09b260678626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores reais:     \", y_test, \"\\n \")\n",
    "print(\"Valores previstos: \", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd01b9c-4826-48f1-af24-255967e3c822",
   "metadata": {},
   "source": [
    "Comparando esses valores  podemos observar que nosso modelo acertou muitas de suas previsões. Para quantificar esa análise, vamos utilizar a métrica: **acurácia**, ou seja, qual o percentual de classes foram corretamente classificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d433c-a094-4509-a367-60ec23ed0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia=100*accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia: \",  ('%.2f' % acuracia), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa18de-6cb7-477e-8621-83e5e68d8686",
   "metadata": {},
   "source": [
    "Podemos observar, portanto, que o nosso modelo obteve uma acurácia superior a 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310e2f6-c6f4-456a-9867-a69cc4b1724d",
   "metadata": {},
   "source": [
    "# Discussão e Próximos Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa32b6d-de55-42a3-b655-e25e8b9e2f7f",
   "metadata": {},
   "source": [
    "Neste material percorremos um exemplo completo de *Machine Learning* desde o carregamento do dataset, passamos pelo treinamento do modelo, pela etapa de predição e finalizamos com a avaliação do mesmo. \n",
    "\n",
    "Entretanto, destacamos que os objetivos desse material são: i)  apresentar a biblioteca `Scikit-Learn`; e ii) discutir os principais passos para execução de um processo de *Machine Learning*, sem entrar em detalhes do algoritmo em si. \n",
    "\n",
    "Entretanto, destacamos que no próximo Módulo de nosso curso iremos fazer uma imersão teórico-prática em alguns dos principais algortimos de *Machine Learning* usados para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b621d-8df2-4380-860e-b644a9185ff8",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7afd3-e19c-4674-9baf-3beeaf433466",
   "metadata": {},
   "source": [
    "## Direitos Autorais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e029a2e-eb2e-4898-abaa-c15a796dd1d4",
   "metadata": {},
   "source": [
    "[APL Data Intelligence](https://linktr.ee/APLdataintelligence)&#8482;  2021. Este notebook Python e seu código fonte estão liberados sob os termos da [Licença do MIT](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
