{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../imagens/logo_APL.png\" width=\"300\" alt=\"APL logo\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de Modelos de Classificação\n",
    "\n",
    "**Bem vindo!** Neste material você usará os 3 classificadores vistos (SVM,  KNN e Árvore de Decisão) em três conjuntos de dados sintéticos. Ao final, espera-se que você seja capaz de entender como utilizar métricas de desempenho para fazer uma análise comparativa entre diferentes algoritimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conteúdo:</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ul>\n",
    "    <li> Introdução </li>\n",
    "    <li> Criação de Dados Sintéticos </li> \n",
    "    <li> Escolha dos Classificadores </li>\n",
    "    <li> Procedimento Experimental </li>  \n",
    "    <li> Discussão </li>  \n",
    "    <li> Considerações Finais </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Já vimos  como a biblioteca `scikit-learn` facilita as etapas de treinamento e avaliação dos modelos. \n",
    "\n",
    "Para a classificação, a acurácia é uma das medidas básicas de desempenho. Essa métrica indica o percentual de classes que foram corretamente classificadas. Ela pode ser calculada da seguinte forma:\n",
    "\n",
    "<center>\n",
    "    <img src=\"../imagens/acuracia-1.png\" width=\"300\" alt=\"Acurácia\"  />\n",
    "</center>\n",
    "\n",
    "Neste material você usará a acurácia para análise comparativa do desempenho dos classificadores estudados ao longo do nosso curso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar as bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Criação dos Dados Sintéticos\n",
    "\n",
    "Serão criados 3 conjuntos de dados com o auxílio das funções `make_moons`, `make_circles` e `make_classification` da biblioteca `scikit-learn`. Essas funções são preprogramadas para gerar dados em formatos específicos que podem ser usados para testes de modelos simples. \n",
    "\n",
    "Em cada dataset os dados serão divididos em duas classes. Trata-se, portanto, de um problema de classificação binária.\n",
    "\n",
    "Finalmente, cada dataset é formado pela `tupla (X, y)`, em que:\n",
    "- `X` representa os regressores (a matriz de dados de entrada); e\n",
    "- `y` a variável alvo (ou vetor de saída).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha dos Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incialmente, vamos definir os nomes para identificarmos os algoritmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"KNN\", \"SVM\", \"Árvore de Decisão\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora definir os construtores dos algoritmos que vamos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(), \n",
    "    SVC(), \n",
    "    DecisionTreeClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos definir os nossos datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1),\n",
    "            make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.3, factor=0.5, random_state=1)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedimento Experimental\n",
    "\n",
    "O processo se dará da seguinte forma:\n",
    "\n",
    "- Será feito um laço para passar por cada um dos 3 dataset criados, nessa etapa os dados serão separados entre conjunto de dados e conjunto de treino.\n",
    "- Dentro do primeiro laço haverá um segundo que irá passar pelos modelos de classficação, aqui serão feitos os treinamentos.\n",
    "\n",
    "Com isso, cada modelo passará por cada dataset em sequência.\n",
    "\n",
    "A visualização será dada pela função <code>scatter</code>, as classes serão identificadas por cores.\n",
    "\n",
    "Ao final, será possível ver também os limites (ou **regiões de classificação**) que cada modelo gerou para cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# Laço em cima dos datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # Separação dos datasets em treino/teste\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    # Plotando os datasets\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Dados de entrada\", fontsize=30)\n",
    "    # Plota os dados de teste\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "    # Plota os dados de treinamento\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    # Laço em cima dos modelos\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # [Curiosidade] Essa parte está fazendo a superfície de decisão, onde \n",
    "        # é possível ver como cada modelo está fazendo a classificação dos dados.\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plota os dados de treino\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "        # Plota os dados de teste\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, edgecolors='w', alpha=0.5)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name, fontsize=30)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'), \n",
    "                size=15, horizontalalignment='right', fontsize=25)\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussão\n",
    "\n",
    "Você pode observar a métrica de desempenho no canto inferior. Pode-se concluir, portanto, que os algoritmos obtiverem desempenho equivalente para o primeiro dataset. O algoritmo KNN obteve desempenho melhor na segunda base de dados, enquanto o algoritmo SVM na terceira.\n",
    "\n",
    "## Considerações Finais\n",
    "\n",
    "Neste material vimos como a biblioteca `scikit-learn` possui métodos projetados para auxiliar o programador ao longo do processo de *Machine Learning*. Fizemos uma análise comparativa dos 3 classificadores estudadosa ao longo do nosso curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direitos Autorais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[APL Data Intelligence](https://linktr.ee/APLdataintelligence)&#8482;  2021. Este notebook Python e seu código fonte estão liberados sob os termos da [Licença do MIT](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
