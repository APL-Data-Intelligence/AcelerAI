{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../imagens/logo_APL.png\" width=\"300\" alt=\"APL logo\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hf8pctt-RAV1",
    "papermill": {
     "duration": 0.048717,
     "end_time": "2021-02-27T10:40:11.273144",
     "exception": false,
     "start_time": "2021-02-27T10:40:11.224427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predição de desgaste em uma máquina CNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bem vindo!** Neste material você aplicará todo o conhecimento obtido ao longo de nosso curso a um projeto real em ciência de dados para **predição de desgaste em uma máquina CNC**. Ao final, espera-se que você entenda os principais passos em cada uma das etapas desse processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conteúdo:</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ul>\n",
    "    <li> Introdução </li>\n",
    "    <li> Entendendo e Carregando o Dataset </li> \n",
    "    <li> Análise Exploratória dos Dados </li>\n",
    "    <li> Regressores (Matriz de entrada) e Variável Alvo (vetor de saídas) </li>  \n",
    "    <li> Dividir o Dataset: Treinamento e Validação </li>   \n",
    "    <li> Algoritmo de Machine Learning </li>  \n",
    "    <li> Avaliação </li>  \n",
    "    <li> Representação: Árvore de Decisão </li>  \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuH_SXJkRAV3",
    "papermill": {
     "duration": 0.046793,
     "end_time": "2021-02-27T10:40:11.368035",
     "exception": false,
     "start_time": "2021-02-27T10:40:11.321242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVOzwkf3RAV4",
    "papermill": {
     "duration": 0.047132,
     "end_time": "2021-02-27T10:40:11.462676",
     "exception": false,
     "start_time": "2021-02-27T10:40:11.415544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "O projeto escolhido consiste na previsão de desgaste de broca em uma máquina CNC de acordo com várias medições de variáveis elétricas e mecânicas feitas ao longo do processo de fresamento de uma peça. Esse modelo pode ser útil na automação da troca de brocas, tornando o processo mais eficiente e possivelmente independente da intervenção humana. \n",
    "\n",
    "Para treinar o modelo usaremos o dataset disponibilizado pela [University of Michigan](https://www.kaggle.com/shasun/tool-wear-detection-in-cnc-mill) em que foram gravados dados de 18 experimentos para fresamento de um tabloide de cera num formato de \"S”, de acordo com a figura:\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img src=\"../imagens/S_Shape.png\" width=\"200\" alt=\"S Shape\"  />\n",
    "</center>\n",
    "\n",
    "Inicialmente, vamos carregar as bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hb-TWZGkRAV5",
    "papermill": {
     "duration": 1.35106,
     "end_time": "2021-02-27T10:40:12.955974",
     "exception": false,
     "start_time": "2021-02-27T10:40:11.604914",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMwKO8FSRAV6",
    "papermill": {
     "duration": 0.047522,
     "end_time": "2021-02-27T10:40:13.051196",
     "exception": false,
     "start_time": "2021-02-27T10:40:13.003674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Entendendo e Carregando o Dataset\n",
    "\n",
    "O dataset consiste de 18 experimentos de usinagem em blocos de cera nas dimensões 5.08 x 5.08 x 3.81 cm. \n",
    "\n",
    "Os parâmetros variados em cada experimento foram:\n",
    "- Condição da broca como desgastada ou não\n",
    "- Velocidade do spindle relativo à peça\n",
    "- Pressão que segura a peça\n",
    "\n",
    "As informações de cada experimento podem ser divididas em:\n",
    "* Entradas: i) No: número do experimentoç ii) `material`: cera (wax); iii) `feed_rate`: velocidade do spindle; e iv) - `clamp_pressure`: pressão que segura a peça.\n",
    "* Saídas: `tool_condition`: unworn ou wornç ii) `machining_completed`: indicador de se a usinagem foi completada; iii) `passed_visual_inspection`: indicador de se a peça passou por inspeção visual.\n",
    "\n",
    "Cada arquivo do experimento contém dados de séries temporais relativas a várias medições de variáveis elétricas e mecânicas feitas ao longo do processo de fresamento de uma peça, coletados com um período de amostragem de 100 ms.\n",
    "\n",
    "Agora vamos carregar os dados do arquivo CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oQmob1FRAV7",
    "papermill": {
     "duration": 0.084271,
     "end_time": "2021-02-27T10:40:13.278005",
     "exception": false,
     "start_time": "2021-02-27T10:40:13.193734",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = 'https://raw.githubusercontent.com/APL-Data-Intelligence/AceleraAI/main/Curso_NEED/datasets/cnc_dataset/'\n",
    "df=pd.read_csv(prefix + 'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K87ThANfRAV7",
    "papermill": {
     "duration": 0.05001,
     "end_time": "2021-02-27T10:40:13.377551",
     "exception": false,
     "start_time": "2021-02-27T10:40:13.327541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vamos usar o método `.info()` para descrição sucinta das principais variáveis de nosso dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1m0Uvl8RAV7",
    "outputId": "9af9ca3b-04eb-48af-db1c-c711de4cfd87",
    "papermill": {
     "duration": 0.077063,
     "end_time": "2021-02-27T10:40:13.503079",
     "exception": false,
     "start_time": "2021-02-27T10:40:13.426016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETKLXPX2RAV9",
    "papermill": {
     "duration": 0.048133,
     "end_time": "2021-02-27T10:40:13.808822",
     "exception": false,
     "start_time": "2021-02-27T10:40:13.760689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode perceber, algumas das *features* desse dataset (**tool_condition**,  **machining_finalized**, **feedrate** e **clamp_pressure**) são variáveis categóricas. Infelizmente, alguns algoritmos da `Scikit-Learn` não lidam com variáveis categóricas. \n",
    "\n",
    "Mas podemos converter essas variáveis categóricas em valores numéricos. Para tanto, vamos usar o método `preprocessing.LabelEncoder()` da biblioteca `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZS2bTT0RAV-",
    "papermill": {
     "duration": 0.064011,
     "end_time": "2021-02-27T10:40:14.018040",
     "exception": false,
     "start_time": "2021-02-27T10:40:13.954029",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le2=LabelEncoder()\n",
    "le2.fit(df['tool_condition'])\n",
    "df['Encoded_tool_condition']=le2.transform(df['tool_condition'])\n",
    "\n",
    "le3=LabelEncoder()\n",
    "le3.fit(df['machining_finalized'])\n",
    "df['Encoded_machining_finalized']=le3.transform(df['machining_finalized'])\n",
    "\n",
    "le4=LabelEncoder()\n",
    "le4.fit(df['feedrate'])\n",
    "df['Encoded_feedrate']=le4.transform(df['feedrate'])\n",
    "\n",
    "le5=LabelEncoder()\n",
    "le5.fit(df['clamp_pressure'])\n",
    "df['Encoded_clamp_pressure']=le5.transform(df['clamp_pressure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-MaK3MzRAV-",
    "papermill": {
     "duration": 0.04847,
     "end_time": "2021-02-27T10:40:14.115457",
     "exception": false,
     "start_time": "2021-02-27T10:40:14.066987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vamos agora utilizar o método `.drop()` para remover algumas *features* que não serão mais necessárias. Oberseve que são aquelas *features* que foram convertidas de variáveis categóricas para variáveis numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSa05TYERAV-",
    "outputId": "de0a050d-2684-4894-d4f7-3c812557f918",
    "papermill": {
     "duration": 0.066485,
     "end_time": "2021-02-27T10:40:14.230677",
     "exception": false,
     "start_time": "2021-02-27T10:40:14.164192",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['passed_visual_inspection','tool_condition','material','machining_finalized'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ByRWlOqRAWA",
    "papermill": {
     "duration": 0.051434,
     "end_time": "2021-02-27T10:40:15.356107",
     "exception": false,
     "start_time": "2021-02-27T10:40:15.304673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Agora vamos concatenar todos os 18 experimentos de forma a obter um único dataset. Para tanto, vamos percorrer cada um dos 18 experimentos e adicionar as *features* **Encoded_feedrate** e **Encoded_clamp_pressure** (novamente, fazemos a conversão de variáveis categóricas em numéricas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNW7U_NhRAWA",
    "papermill": {
     "duration": 0.809147,
     "end_time": "2021-02-27T10:40:16.227330",
     "exception": false,
     "start_time": "2021-02-27T10:40:15.418183",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(1,19):\n",
    "    ex_num = '0' + str(i) if i < 10 else str(i)\n",
    "    frame = pd.read_csv(prefix + \"experiment_{}.csv\".format(ex_num))\n",
    "\n",
    "    ex_result_row = df[df['No'] == i]\n",
    "\n",
    "    le6=LabelEncoder()\n",
    "    le6.fit(frame['Machining_Process'])\n",
    "    frame['Encoded_Machining_Process']=le6.transform(frame['Machining_Process'])\n",
    "    frame.drop('Machining_Process', axis=1, inplace=True)\n",
    "\n",
    "    frame['Encoded_feedrate'] = ex_result_row.iloc[0]['Encoded_feedrate']\n",
    "    frame['Encoded_tool_condition'] =ex_result_row.iloc[0]['Encoded_tool_condition']\n",
    "    frame['Encoded_clamp_pressure'] = ex_result_row.iloc[0]['Encoded_clamp_pressure']\n",
    "    frames.append(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY1ti6HtRAWA",
    "papermill": {
     "duration": 0.052223,
     "end_time": "2021-02-27T10:40:16.331448",
     "exception": false,
     "start_time": "2021-02-27T10:40:16.279225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Agora vamos atribuir a lista `frames` (que corresponde aos 18 experimentos) a um novo dataframe `df_final`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGQiz_gwRAWB",
    "outputId": "9273e48b-9552-4ea9-d828-73bacbe8cd04",
    "papermill": {
     "duration": 0.104353,
     "end_time": "2021-02-27T10:40:16.487914",
     "exception": false,
     "start_time": "2021-02-27T10:40:16.383561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = pd.concat(frames, ignore_index=True)\n",
    "print(\"Dimensão do Dataset:\", df_final.shape)\n",
    "print(\"Numero de amostras: \", df_final.shape[0], \" (numero de linhas do dataframe).\")\n",
    "print(\"Numero de features: \", df_final.shape[1], \" (numero de colunas do dataframe).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR57Xjc2RAWC",
    "papermill": {
     "duration": 0.075304,
     "end_time": "2021-02-27T10:40:29.731433",
     "exception": false,
     "start_time": "2021-02-27T10:40:29.656129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vamos, novamente, utilizar o método `.drop()` para remover algumas variáveis que não foram medidas ao longo do experimento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xysxad3SRAWC",
    "papermill": {
     "duration": 0.095676,
     "end_time": "2021-02-27T10:40:29.903925",
     "exception": false,
     "start_time": "2021-02-27T10:40:29.808249",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final.drop(['Z1_CurrentFeedback','Z1_DCBusVoltage','Z1_OutputCurrent',\n",
    "               'Z1_OutputVoltage','S1_SystemInertia'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DZFxHVcORAWC",
    "outputId": "6b7d5ffa-672f-4bba-dcfc-e268e62ebbf6",
    "papermill": {
     "duration": 12.958124,
     "end_time": "2021-02-27T10:40:42.939523",
     "exception": false,
     "start_time": "2021-02-27T10:40:29.981399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\">>>>> Heatmap of frames after drop column <<<<<\")\n",
    "plt.figure(figsize=(50,50))\n",
    "sns.heatmap(df_final.corr(),linewidths=.1,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSlPttx1RAWD",
    "outputId": "0e8e2207-ad74-4636-cbda-3082133bbf80",
    "papermill": {
     "duration": 0.401661,
     "end_time": "2021-02-27T10:40:43.443009",
     "exception": false,
     "start_time": "2021-02-27T10:40:43.041348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pela análise da matriz anterior podemos observar que, de forma geral, existe baixa correlação entre as *features*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd5ohUlOZBgp"
   },
   "source": [
    "## Separar as Colunas do Dataframe \n",
    "#### Regressores (Matriz de entrada) vs Variável Alvo (vetor de saídas).\n",
    "\n",
    "Inicialmente, vamos definir os regressores (matriz de entrada), `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCt76NdWZZ3k",
    "outputId": "df2e313a-4a6d-491a-90f7-fcf8507108cd"
   },
   "outputs": [],
   "source": [
    "X = df_final.drop(['Encoded_tool_condition'], axis=1)\n",
    "print(\"Dimensão dos Regressores (matriz de entradas):\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final.Encoded_tool_condition\n",
    "print(\"Dimensão da variável alvo (vetor de saídas):\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir o Dataset: Treinamento e Validação\n",
    "\n",
    "Vamos dividir nosso dataset em dois subconjuntos: 1) dados de treinamento; e 2) dados de validação.  Para tanto, vamos utilizar o método `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Machine Learning\n",
    "\n",
    "Vamos calcular o tempo de execução de cada algoritmo. Para tanto, vamos usar o método `datatime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos seguir os passos para definição dos nossos algoritmos. \n",
    "\n",
    "Nesse notebook vamos comparar os três algoritmos de Machine Learning estudados ao longo de nosso curso:\n",
    "1. Árvore de Decisão;\n",
    "2. SMV; e\n",
    "3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########  Árvore de Decisão ###################\n",
    "# inciando o temporizador\n",
    "time_start=datetime.now()\n",
    "\n",
    "# Passo 1: Importando o classificador \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Passo 2: Instanciando o Estimador.\n",
    "DT_clf = DecisionTreeClassifier()\n",
    "# Passo 3: Ajustar os parâmetros do modelo a partir dos dados\n",
    "DT_clf.fit(X_train, y_train)\n",
    "# Passo 4: Fazer a predição a partir de um novo comjunto de amostras:\n",
    "DT_y_pred = DT_clf.predict(X_test)\n",
    "print('==========   Árvore de Decisão   =======')\n",
    "# finalizando o temporizador\n",
    "time_end=datetime.now()\n",
    "e= time_end - time_start\n",
    "print(\"Tempo de execução: \",e)\n",
    "\n",
    "################  SVM   ###################\n",
    "# inciando o temporizador\n",
    "time_start=datetime.now()\n",
    "\n",
    "# Passo 1: Importando o classificador\n",
    "from sklearn import svm\n",
    "# Passo 2: Instanciando o Estimador.\n",
    "SVM_clf = svm.SVC()\n",
    "# Passo 3: Ajustar os parâmetros do modelo a partir dos dados\n",
    "SVM_clf.fit(X_train, y_train)\n",
    "# Passo 4: Fazer a predição a partir de um novo comjunto de amostras:\n",
    "SVM_y_pred = SVM_clf.predict(X_test)\n",
    "print('==========   Support Vector Machine   =======')\n",
    "# finalizando o temporizador\n",
    "time_end=datetime.now()\n",
    "e= time_end - time_start\n",
    "print(\"Tempo de execução: \",e)\n",
    "\n",
    "\n",
    "################  KNN   ###################\n",
    "# inciando o temporizador\n",
    "time_start=datetime.now()\n",
    "\n",
    "# Passo 1: Importando o classificador\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Passo 2: Instanciando o Estimador.\n",
    "KNN_clf = KNeighborsClassifier()\n",
    "# Passo 3: Ajustar os parâmetros do modelo a partir dos dados\n",
    "KNN_clf.fit(X_train, y_train)\n",
    "# Passo 4: Fazer a predição a partir de um novo comjunto de amostras:\n",
    "KNN_y_pred = KNN_clf.predict(X_test)\n",
    "print('==========   K Nearest Neighbours   =======')\n",
    "# finalizando o temporizador\n",
    "time_end=datetime.now()\n",
    "e= time_end - time_start\n",
    "print(\"Tempo de execução: \",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0CCZPtjx_Qn"
   },
   "source": [
    "## Avaliação de Desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cálculo da métrica de desempenho vamos usar o método `metrics` da Biblioteca `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos no módulo anterior, o método `metrics.accuracy_score` calcula a acurácia do modelo, ou seja, o percentual de valores previstos que foram iguais aos valores reais. Vamos utilizá-lo para comapração de desempenho entre os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==========   Árvore de Decisão   =======')\n",
    "print(\"Precisão no conjunto de treino: \", 100*metrics.accuracy_score(y_train, DT_clf.predict(X_train)), '%.')\n",
    "print(\"Precisão no conjunto de teste: \", 100*metrics.accuracy_score(y_test, DT_y_pred), '%.')\n",
    "\n",
    "\n",
    "print('==========   Support Vector Machine   =======')\n",
    "print(\"Precisão no conjunto de treino: \", 100*metrics.accuracy_score(y_train, SVM_clf.predict(X_train)), '%.')\n",
    "print(\"Precisão no conjunto de teste: \", 100*metrics.accuracy_score(y_test, SVM_y_pred), '%.')\n",
    "\n",
    "\n",
    "print('==========   K Nearest Neighbours   =======')\n",
    "print(\"Precisão no conjunto de treino: \", 100*metrics.accuracy_score(y_train, KNN_clf.predict(X_train)), '%.')\n",
    "print(\"Precisão no conjunto de teste: \", 100*metrics.accuracy_score(y_test, KNN_y_pred), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-FazQ8VyBwl"
   },
   "source": [
    "## Representação: Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O_tippgdyBA_",
    "outputId": "5ca7d2a1-b74a-4a98-d6a9-0bfbaab695a8"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "plt.figure(figsize=(30,30))\n",
    "tree.plot_tree(DT_clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direitos Autorais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[APL Data Intelligence](https://linktr.ee/APLdataintelligence)&#8482;  2021. Este notebook Python e seu código fonte estão liberados sob os termos da [Licença do MIT](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNC_mill_example_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 120.883995,
   "end_time": "2021-02-27T10:42:06.420944",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-27T10:40:05.536949",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
