{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size=\"5\">Comparar modelos de classificação</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook, você usará os 4 classificadores vistos até aqui: Regressão Logística, SVM, KNN e Árvore de decisão para comparar seus resultados em um conjuntos de dados sintéticos, criados apenas para entendimento e exercício.\n",
    "\n",
    "Através da biblioteca <code>scikit-learn</code> você verá que é bem fácil fazer o treinamento e adaptar o código para receber diferentes modelos de forma compacta sem precisar alterar muito o código."
   ]
  },
  {
   "source": [
    "<h2>Importação das bibliotecas</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2 id=\"load_dataset\">Criação dos dados sintéticos</h2>\n",
    "\n",
    "Os dados para esse notebook serão pontos divididos em duas classes. Serão criados 3 conjuntos aleatórios diferentes, com o auxílio das funções <code>make_moons</code>, <code>make_circles</code> e <code>make_classification</code> da <code>scikit-learn</code>. Essas funções são preprogramadas para gerar dados em formatos específicos que podem ser usados para testes de modelos simples.\n",
    "\n",
    "Cada dataset é formado pela tupla (X, y), onde X são os pontos de entrada e y os de saída.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "names = [\"KNN\", \"SVM\", \"Árvode de decisão\", \"Regressão Logística\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3), \n",
    "    SVC(kernel=\"linear\", C=0.025), \n",
    "    DecisionTreeClassifier(max_depth=5), \n",
    "    LogisticRegression(C=0.01, solver='liblinear')]\n",
    "\n",
    "datasets = [make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1),\n",
    "            make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo se dará da seguinte forma:\n",
    "\n",
    "- Será feito um laço para passar por cada um dos 3 dataset criados, nessa etapa os dados serão separados entre conjunto de dados e conjunto de treino.\n",
    "- Dentro do primeiro laço haverá um segundo que irá passar pelos modelos de classficação, aqui serão feitos os treinamentos.\n",
    "\n",
    "Com isso, cada modelo passará por cada dataset em sequência.\n",
    "\n",
    "A visualização será dada pela função <code>scatter</code>, as classes serão identificadas por cores.\n",
    "\n",
    "A final, será possível ver também os limites que cada modelo gerou para cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# Laço em cima dos datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # Separação dos datasets em treino/teste\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    # Plotando os datasets\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Dados de entrada\")\n",
    "    # Plota os dados de teste\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "    # Plota os dados de treinamento\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # Laço em cima dos modelos\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # [Curiosidade] Essa parte está fazendo a superfície de decisão, onde \n",
    "        # é possível ver como cada modelo está fazendo a classificação dos dados.\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plota os dados de treino\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "        # Plota os dados de teste\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'), size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}